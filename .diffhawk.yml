# DiffHawk Configuration
# Copy this file to .diffhawk.yml and configure your settings

# LLM Provider Configuration
provider: cerebras  # openai | anthropic | gemini | glm
api_key: ${{ env.LLM_API_KEY }}  # Reference to GitHub secret
model: zai-glm-4.6  # Model name for the provider

# Workflow Settings (optional)
workflows:
  pr_description:
    enabled: true
    mode: overwrite

  pr_title:
    auto_generate: true

  approval:
    enabled: true   

  symbol_usage:
    enabled: false
    search_depth: project  # file | project
  
  change_review:
    enabled: true

# General Settings (optional)
settings:
  ignore_paths:
    - "node_modules/**"
    - "vendor/**"
    - "*.generated.*"
    - "dist/**"
    - "build/**"
  severity_threshold: warning  # info | warning | error

# Pattern Preferences (optional)
preferences:
  patterns:
    nested_conditionals:
      rule: avoid
      max_depth: 2
      reason: "Use early returns or guard clauses"
    
    function_length:
      rule: require
      max_lines: 50
      reason: "Keep functions focused and testable"
  
  naming:
    functions: snake_case
    classes: PascalCase
    constants: SCREAMING_SNAKE_CASE
